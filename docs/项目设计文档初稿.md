# 项目总体设计文档

## 项目概述

基于 StackOverflow 上的数据（这里特指具体的回答内容），构建针对编程中出现的各类异常/报错的自动原因预测与分析系统

## 实现路径

### 前端开发

拟采用 Vue.js 框架进行前端开发（官方文档：https://vuejs.org/）

- Vue.js 是一个用于构建用户界面的 JavaScript 框架，它建立在标准 HTML、CSS 和 JavaScript 之上

-  Vue.js 提供声明性和基于组件的编程模型，能够高效地开发用户界面

### 后端开发

拟采用 FastAPI 框架进行后端开发（官方文档：https://fastapi.tiangolo.com/zh/）

- FastAPI 是一个用于构建 API 的现代、快速（高性能）的 web 框架，使用 Python 3.6+ 并基于标准的 Python 类型提示

- FastAPI 有可与 NodeJS 和 Go 并肩的极高性能（归功于 Starlette 和 Pydantic），是最快的 Python web 框架之一

### 知识图谱构建

拟选用 Neo4j 作为存储知识图谱的图数据库，官网有免费的云端实例可以使用，免于本地安装和部署（https://neo4j.com/）

从 StackOverflow 上爬取相关的高质量回答，进行人工/AI标注，具体标注内容和方法有待商榷和进一步讨论

根据标注结果形成完整的知识图谱数据，用于向图数据库注入数据

免费的 Neo4j 图数据库实例提供了知识图谱的可视化展示和操作页面

### 核心技术原型

在使用大语言模型（LLM）构建问答系统的时候，往往会遇到 LLM 缺少对相关领域知识了解的问题，以及 LLM 在回答问题中的幻觉问题，而知识图谱（KG）则能够克服这两个问题，相反知识图谱在问答系统中缺乏的正是 LLM 所拥有的泛化性和聊天式的流畅的语言组织能力，因此 LLM 与 KG 的结合（Graph RAG）成为了一种新兴的有效的构建问答系统的方式

Graph RAG 的相关工作流：用户 --(问题)--> LLM --(检索)--> KG --(检索结果)--> LLM --(回答)--> 用户

其中，检索操作可以基于关键字/嵌入进行匹配，检索结果为整个知识图谱中某个深度的子图，回答由 LLM 根据检索结果组织语言生成

相关实现在 LlamaIndex 中可以找到参考：https://github.com/jerryjliu/llama_index/tree/main

参考资料

- https://siwei.io/graph-rag/

- https://siwei.io/graph-enabled-llama-index/

- https://siwei.io/llm-text-to-nebulagraph-query/

### 持续集成与部署

拟采用 docker 的方式进行部署（具体细节有待讨论）

拟采用 Jenkins 进行持续集成和部署（具体细节有待讨论）

